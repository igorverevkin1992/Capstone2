{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 2 Modeling\n",
    "\n",
    "In this notebook we will perform modeling step of the data science method. The goal of this step is to develop a final model that effectively predicts our patients' class - 'positive'(1) or 'negative'(0). In the previous step we have already built two models - LogisticRegressionCassifier (which was out baseline model) and RandomForestClassifier. We assesed the performance of each of these models first without tuning and than with hyperparameter tuning using GridSearchCV for LogisticRegression and RandomizedSearchCV for RandomForest and obtained results using classification report. We noticed, that both models performed better with hyperparameter tuning, and RandomForest showed significantly better results in precision, recall and f1-score than LogisticRegression. We also saved our train_test_split as well as both our models as pickle files.\n",
    "\n",
    "In this step we will built two other models - GradientBoostingClassifier and AdaBoostClassifer, use hyperparameter tuning in order to enhance their performance and compare their results with the results of two above mentioned models that we built durint preprocessing and trainin data development step. \n",
    "\n",
    "We will use standard metrics in order to asses our classification models performance - accuracy score, precision, recall and f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, RandomizedSearchCV, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load our encoded dataset, train_test_split and two models - RandomForest and LogisticRegression - that we built on preprocessing and training data development step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../EDA/Diabetes_EDA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden weight loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital thrush</th>\n",
       "      <th>visual blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed healing</th>\n",
       "      <th>partial paresis</th>\n",
       "      <th>muscle stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Polyuria  Polydipsia  sudden weight loss  weakness  \\\n",
       "0   40       0         0           1                   0         1   \n",
       "1   58       0         0           0                   0         1   \n",
       "2   41       0         1           0                   0         1   \n",
       "3   45       0         0           0                   1         1   \n",
       "4   60       0         1           1                   1         1   \n",
       "\n",
       "   Polyphagia  Genital thrush  visual blurring  Itching  Irritability  \\\n",
       "0           0               0                0        1             0   \n",
       "1           0               0                1        0             0   \n",
       "2           1               0                0        1             0   \n",
       "3           1               1                0        1             0   \n",
       "4           1               0                1        1             1   \n",
       "\n",
       "   delayed healing  partial paresis  muscle stiffness  Alopecia  Obesity  \\\n",
       "0                1                0                 1         1        1   \n",
       "1                0                1                 0         1        0   \n",
       "2                1                0                 1         1        0   \n",
       "3                1                0                 0         0        0   \n",
       "4                1                1                 1         1        1   \n",
       "\n",
       "   class  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading train_test_split\n",
    "with open('../Splits/Train_Test_Split.pkl', 'rb') as tts_pickle:\n",
    "    tts = pickle.load(tts_pickle)\n",
    "#loading RandomForestClassifier\n",
    "with open('../Models/Diabetes_RandFor.pkl', 'rb') as rfc_pickle:\n",
    "    rfc = pickle.load(rfc_pickle)\n",
    "#loading LogisticRegression\n",
    "with open('../Models/Diabetes_LogReg.pkl', 'rb') as lr_pickle:\n",
    "    lr = pickle.load(lr_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=340, max_features='sqrt', n_estimators=600,\n",
       "                       oob_score=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100]})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_ypred = rfc.predict(X_test)\n",
    "lr_ypred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see classification reports for each of these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== RANDOM FOREST CLASSIFICATION REPORT =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        40\n",
      "           1       1.00      0.98      0.99        64\n",
      "\n",
      "    accuracy                           0.99       104\n",
      "   macro avg       0.99      0.99      0.99       104\n",
      "weighted avg       0.99      0.99      0.99       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('====== RANDOM FOREST CLASSIFICATION REPORT =====')\n",
    "print(classification_report(y_test, rfc_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== LOGISTIC REGRESSION CLASSIFICATION REPORT =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93        40\n",
      "           1       0.98      0.92      0.95        64\n",
      "\n",
      "    accuracy                           0.94       104\n",
      "   macro avg       0.93      0.95      0.94       104\n",
      "weighted avg       0.95      0.94      0.94       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('====== LOGISTIC REGRESSION CLASSIFICATION REPORT =====')\n",
    "print(classification_report(y_test, lr_ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know from the previous step, our RandomForestClassifier showed significantly better results than LogisticRegression model. Now we will build two more models. We will start with GradientBoostingClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize our model, fit it to the training set and see how it performs. We will not use any hyperparameter tuning now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "gbc.fit(X_train, y_train)\n",
    "gbc_ypred_train = gbc.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== GBC TRAINING SET ACCURACY SCORE =====\n",
      "1.0\n",
      "===== GBC TRAINING SET CLASSIFICATION REPORT =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       160\n",
      "           1       1.00      1.00      1.00       256\n",
      "\n",
      "    accuracy                           1.00       416\n",
      "   macro avg       1.00      1.00      1.00       416\n",
      "weighted avg       1.00      1.00      1.00       416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('===== GBC TRAINING SET ACCURACY SCORE =====')\n",
    "print(accuracy_score(y_train, gbc_ypred_train))\n",
    "print('===== GBC TRAINING SET CLASSIFICATION REPORT =====')\n",
    "print(classification_report(y_train, gbc_ypred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have perfect results on our training set. Now let's see how the model perform on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_ypred_test = gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== GBC TEST SET ACCURACY SCORE =====\n",
      "0.9903846153846154\n",
      "===== GBC TEST SET CLASSIFICATION REPORT =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        40\n",
      "           1       1.00      0.98      0.99        64\n",
      "\n",
      "    accuracy                           0.99       104\n",
      "   macro avg       0.99      0.99      0.99       104\n",
      "weighted avg       0.99      0.99      0.99       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('===== GBC TEST SET ACCURACY SCORE =====')\n",
    "print(accuracy_score(y_test, gbc_ypred_test))\n",
    "print('===== GBC TEST SET CLASSIFICATION REPORT =====')\n",
    "print(classification_report(y_test, gbc_ypred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are slightly worse, but there is no significant gaps between our train and test sets results. We can conclude that even generic model with no hyperparameters tuning is able to generalize on new data and show great results. However, we will still perform parameters tuning just in the sake of comparing models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ccp_alpha', 'criterion', 'init', 'learning_rate', 'loss', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_iter_no_change', 'presort', 'random_state', 'subsample', 'tol', 'validation_fraction', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, GradientBoostingClassifier's parameters are very similar to RandomForestClassifier parameters. For our goal we are mostly interested in n_estimators, learning_rate, max_features and max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of trees\n",
    "n_estimators = [int(i) for i in np.linspace(200, 2000, 10)]\n",
    "\n",
    "#learning rates\n",
    "learning_rate = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "#number of features for each split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "#maximal depth\n",
    "max_depth = [int(i) for i in np.linspace(100, 500, 11)]\n",
    "\n",
    "#parameters grid\n",
    "param_grid = {'n_estimators':n_estimators, 'learning_rate':learning_rate, 'max_features':max_features, 'max_depth':max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=42),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.05, 0.1, 0.25, 0.5,\n",
       "                                                          0.75, 1],\n",
       "                                        'max_depth': [100, 140, 180, 220, 260,\n",
       "                                                      300, 340, 380, 420, 460,\n",
       "                                                      500],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_rand = RandomizedSearchCV(estimator=gbc, param_distributions=param_grid, n_iter=100, cv=5, random_state=42, n_jobs=-1)\n",
    "gbc_rand.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200, 'max_features': 'sqrt', 'max_depth': 500, 'learning_rate': 0.05}\n"
     ]
    }
   ],
   "source": [
    "print(gbc_rand.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained the best parameters for our GradientBoostingClassifier. Now let's plug those parameters into our model and asses its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_params = GradientBoostingClassifier(n_estimators=200, learning_rate = 0.05, max_features='sqrt', max_depth = 500, random_state = 42)\n",
    "gbc_params.fit(X_train, y_train)\n",
    "gbc_params_ypred = gbc_params.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== GBC_PARAMS TEST SET ACCURACY SCORE =====\n",
      "1.0\n",
      "===== GBC_PARAMS TEST SET CLASSIFICATION REPORT =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           1.00       104\n",
      "   macro avg       1.00      1.00      1.00       104\n",
      "weighted avg       1.00      1.00      1.00       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('===== GBC_PARAMS TEST SET ACCURACY SCORE =====')\n",
    "print(accuracy_score(y_test, gbc_params_ypred))\n",
    "print('===== GBC_PARAMS TEST SET CLASSIFICATION REPORT =====')\n",
    "print(classification_report(y_test, gbc_params_ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the classification report we can see, that tuning the model's parameters improved its performance and we got perfect scores on the test set. This model showed the best results among all the models we used so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to build AdaBoost model and see how it's going to perform. Again, we will not tune hyperparameters first and will check how the model performs on train and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ABC TRAINING SET ACCURACY SCORE =====\n",
      "0.9471153846153846\n",
      "===== ABC TRAINING SET CLASSIFICATION REPORT =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93       160\n",
      "           1       0.97      0.95      0.96       256\n",
      "\n",
      "    accuracy                           0.95       416\n",
      "   macro avg       0.94      0.95      0.94       416\n",
      "weighted avg       0.95      0.95      0.95       416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(random_state=42)\n",
    "abc.fit(X_train, y_train)\n",
    "abc_ypred_train = abc.predict(X_train)\n",
    "print('===== ABC TRAINING SET ACCURACY SCORE =====')\n",
    "print(accuracy_score(y_train, abc_ypred_train))\n",
    "print('===== ABC TRAINING SET CLASSIFICATION REPORT =====')\n",
    "print(classification_report(y_train, abc_ypred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostClassifier showed good results on the trainin set. Let's see how it's going to work on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ABC TEST SET ACCURACY SCORE =====\n",
      "0.9519230769230769\n",
      "===== ABC TEST SET CLASSIFICATION REPORT =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        40\n",
      "           1       1.00      0.92      0.96        64\n",
      "\n",
      "    accuracy                           0.95       104\n",
      "   macro avg       0.94      0.96      0.95       104\n",
      "weighted avg       0.96      0.95      0.95       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abc_ypred_test = abc.predict(X_test)\n",
    "print('===== ABC TEST SET ACCURACY SCORE =====')\n",
    "print(accuracy_score(y_test, abc_ypred_test))\n",
    "print('===== ABC TEST SET CLASSIFICATION REPORT =====')\n",
    "print(classification_report(y_test, abc_ypred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although accuracy score improved a little bit, we can see that some of the results got worse. Overall, there are no significant gaps in model performance on train and test splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will tune hyperparameters of AdaBoostingClassifier and check if it's goint to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['algorithm', 'base_estimator', 'learning_rate', 'n_estimators', 'random_state'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "              \"learning_rate\": [0.05, 0.1, 0.25, 0.5, 0.75, 1],\n",
    "              \"n_estimators\": [int(i) for i in np.linspace(200, 2000, 10)]\n",
    "             }\n",
    "\n",
    "\n",
    "weak_c = DecisionTreeClassifier(random_state = 42, max_features = \"auto\", class_weight = \"balanced\", max_depth = 3)\n",
    "\n",
    "ABC = AdaBoostClassifier(base_estimator = weak_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 600, 'learning_rate': 0.5, 'base_estimator__splitter': 'best', 'base_estimator__criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "abc_rand = RandomizedSearchCV(estimator=ABC, param_distributions=param_grid, n_iter=40, cv=5, scoring='roc_auc', random_state=42)\n",
    "abc_rand.fit(X_train, y_train)\n",
    "print(abc_rand.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plug those parameters into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_est = DecisionTreeClassifier(random_state=42, max_features='auto', class_weight='balanced', max_depth=3, splitter='best', criterion='entropy')\n",
    "abc_params = AdaBoostClassifier(base_estimator=base_est, n_estimators=600, learning_rate=0.5, random_state=42)\n",
    "abc_params.fit(X_train, y_train)\n",
    "abc_params_ypred = abc_params.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ABC_PARAMS TEST SET ACCURACY SCORE =====\n",
      "1.0\n",
      "===== ABC_PARAMS TEST SET CLASSIFICATION REPORT =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           1.00       104\n",
      "   macro avg       1.00      1.00      1.00       104\n",
      "weighted avg       1.00      1.00      1.00       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('===== ABC_PARAMS TEST SET ACCURACY SCORE =====')\n",
    "print(accuracy_score(y_test, abc_params_ypred))\n",
    "print('===== ABC_PARAMS TEST SET CLASSIFICATION REPORT =====')\n",
    "print(classification_report(y_test, abc_params_ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that tuned AdaBoostClassifier shows better results than not tuned one. Again, just as with GradientBoostingClassifier, hyperparameters tuning allowed us to achieve perfect score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among all models that we built, GradientBoostingClassifier and AdaBoostClassifier showed the highest results - 100% on the train and test sets after hyperparameters tuning. Those two are the best models we've built and it would make sense to implement one of them for our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE SELECTION "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
